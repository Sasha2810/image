{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":425593,"sourceType":"datasetVersion","datasetId":190814}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-11-13T20:36:01.425697Z","iopub.execute_input":"2024-11-13T20:36:01.426045Z","iopub.status.idle":"2024-11-13T20:36:01.794847Z","shell.execute_reply.started":"2024-11-13T20:36:01.426017Z","shell.execute_reply":"2024-11-13T20:36:01.793930Z"},"trusted":true},"outputs":[{"name":"stdout","text":"/kaggle/input/russian-language-toxic-comments/labeled.csv\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nfile_path = '/kaggle/input/russian-language-toxic-comments/labeled.csv'\ndf = pd.read_csv(file_path)\n\nprint(df.head())\n\nX = df.drop('toxic', axis=1)  \ny = df['toxic']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\nprint(f'Размер обучающей выборки: {X_train.shape}')\nprint(f'Размер тестовой выборки: {X_test.shape}')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T20:36:03.101654Z","iopub.execute_input":"2024-11-13T20:36:03.102579Z","iopub.status.idle":"2024-11-13T20:36:03.325300Z","shell.execute_reply.started":"2024-11-13T20:36:03.102546Z","shell.execute_reply":"2024-11-13T20:36:03.324255Z"},"trusted":true},"outputs":[{"name":"stdout","text":"                                             comment  toxic\n0               Верблюдов-то за что? Дебилы, бл...\\n    1.0\n1  Хохлы, это отдушина затюканого россиянина, мол...    1.0\n2                          Собаке - собачья смерть\\n    1.0\n3  Страницу обнови, дебил. Это тоже не оскорблени...    1.0\n4  тебя не убедил 6-страничный пдф в том, что Скр...    1.0\nРазмер обучающей выборки: (12970, 1)\nРазмер тестовой выборки: (1442, 1)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import f1_score\nfrom tqdm import tqdm\n\n\nprint(f'Количество строк в данных: {df.shape[0]}')\nprint(f'Столбцы данных: {df.columns.tolist()}')\n\nX = df['comment']  \ny = df['toxic'].apply(int)\n\nprint(f'Количество пропущенных значений в X: {X.isnull().sum()}')\nprint(f'Количество пропущенных значений в y: {y.isnull().sum()}')\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\n\nprint(f'Размер обучающей выборки: {X_train.shape[0]}')\nprint(f'Размер тестовой выборки: {X_test.shape[0]}')\n\nvectorizer = TfidfVectorizer()\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\nprint(f'Размеры X_train_tfidf: {X_train_tfidf.shape}')\nprint(f'Размеры X_test_tfidf: {X_test_tfidf.shape}')\n\nlog_reg = LogisticRegression(max_iter=1000)\nlog_reg.fit(X_train_tfidf, y_train)\ny_pred_log_reg = log_reg.predict(X_test_tfidf)\nf1_log_reg = f1_score(y_test, y_pred_log_reg)\nprint(f'F1-score для Логистической регрессии: {f1_log_reg:.4f}')\n\ntree_clf = DecisionTreeClassifier()\ntree_clf.fit(X_train_tfidf, y_train)\ny_pred_tree_clf = tree_clf.predict(X_test_tfidf)\nf1_tree_clf = f1_score(y_test, y_pred_tree_clf)\nprint(f'F1-score для Дерева решений: {f1_tree_clf:.4f}')\n","metadata":{"execution":{"iopub.status.busy":"2024-11-13T20:36:20.437236Z","iopub.execute_input":"2024-11-13T20:36:20.437596Z","iopub.status.idle":"2024-11-13T20:36:31.609439Z","shell.execute_reply.started":"2024-11-13T20:36:20.437569Z","shell.execute_reply":"2024-11-13T20:36:31.608461Z"},"trusted":true},"outputs":[{"name":"stdout","text":"Количество строк в данных: 14412\nСтолбцы данных: ['comment', 'toxic']\nКоличество пропущенных значений в X: 0\nКоличество пропущенных значений в y: 0\nРазмер обучающей выборки: 12970\nРазмер тестовой выборки: 1442\nРазмеры X_train_tfidf: (12970, 63804)\nРазмеры X_test_tfidf: (1442, 63804)\nF1-score для Логистической регрессии: 0.6773\nF1-score для Дерева решений: 0.5784\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"vectorizer = TfidfVectorizer(max_features=20000, ngram_range=(1, 2))\nX_train_tfidf = vectorizer.fit_transform(X_train)\nX_test_tfidf = vectorizer.transform(X_test)\n\nmodel = LogisticRegression()\nmodel.fit(X_train_tfidf, y_train)\n\ny_pred = model.predict(X_test_tfidf)\nf1 = f1_score(y_test, y_pred)\nprint(f'F1-score для TF-IDF + Logistic Regression: {f1:.4f}')","metadata":{"execution":{"iopub.status.busy":"2024-11-13T20:37:31.864709Z","iopub.execute_input":"2024-11-13T20:37:31.865055Z","iopub.status.idle":"2024-11-13T20:37:34.786934Z","shell.execute_reply.started":"2024-11-13T20:37:31.865029Z","shell.execute_reply":"2024-11-13T20:37:34.785615Z"},"trusted":true},"outputs":[{"name":"stdout","text":"F1-score для TF-IDF + Logistic Regression: 0.6870\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils.class_weight import compute_class_weight\nfrom transformers import Trainer, TrainingArguments, BertTokenizer, BertForSequenceClassification, get_linear_schedule_with_warmup\nfrom datasets import Dataset\nimport torch\nfrom torch.nn import CrossEntropyLoss\n\n# Загрузка и предобработка данных\nfile_path = '/kaggle/input/russian-language-toxic-comments/labeled.csv'\ndf = pd.read_csv(file_path)\nX = df['comment']\ny = df['toxic'].astype(int)\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=42)\nX_train","metadata":{"execution":{"iopub.status.busy":"2024-11-13T20:58:21.436580Z","iopub.execute_input":"2024-11-13T20:58:21.436932Z","iopub.status.idle":"2024-11-13T20:58:21.530980Z","shell.execute_reply.started":"2024-11-13T20:58:21.436906Z","shell.execute_reply":"2024-11-13T20:58:21.530037Z"},"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"4194     Парадоксальная ситуация. У меня все лампы что ...\n8396     Работодатель может поднимать вакансии и эта да...\n2798       15 и повышение в должности. Отлично работаем!\\n\n5958     Русачки ебаные, какого хуя вы отдали Польше мо...\n8523     играться то че не так, судя по фото видео они ...\n                               ...                        \n5191     Ну не знаю. А откуда тогда машин столько у люд...\n13418    А у меня кандидатка завалилась на электрохроми...\n5390                          Второй сезон полная хуета!\\n\n860      Мда... Хотел просто спасибо сказать, но и тут ...\n7270     Не, год это прямо максимум максимум. В среднем...\nName: comment, Length: 12970, dtype: object"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"# Настройка модели и токенизатора\nmodel_name = \"cointegrated/rubert-tiny2\"\ntokenizer = BertTokenizer.from_pretrained(model_name)\nmodel = BertForSequenceClassification.from_pretrained(model_name, num_labels=2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Задаем dropout для уменьшения переобучения\nmodel.config.hidden_dropout_prob = 0.3\n\n# Подготовка данных для модели\ntrain_data = Dataset.from_pandas(pd.DataFrame({'text': X_train, 'label': y_train}))\ntest_data = Dataset.from_pandas(pd.DataFrame({'text': X_test, 'label': y_test}))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T20:59:29.633871Z","iopub.execute_input":"2024-11-13T20:59:29.634263Z","iopub.status.idle":"2024-11-13T20:59:29.684867Z","shell.execute_reply.started":"2024-11-13T20:59:29.634230Z","shell.execute_reply":"2024-11-13T20:59:29.684109Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Функция токенизации с уменьшенной длиной для экономии памяти\ndef tokenize(batch):\n    return tokenizer(batch['text'], padding=True, truncation=True, max_length=128)\n\ntrain_data = train_data.map(tokenize, batched=True, batch_size=len(train_data))\ntest_data = test_data.map(tokenize, batched=True, batch_size=len(test_data))\n\ntrain_data.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])\ntest_data.set_format('torch', columns=['input_ids', 'attention_mask', 'label'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T20:59:59.355549Z","iopub.execute_input":"2024-11-13T20:59:59.355918Z","iopub.status.idle":"2024-11-13T21:00:19.398497Z","shell.execute_reply.started":"2024-11-13T20:59:59.355891Z","shell.execute_reply":"2024-11-13T21:00:19.397642Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/12970 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eed96f649b7b4dd787a451ebb7593cf3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/1442 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"432c78cce6174defa6f7368d6548cbf9"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"training_args = TrainingArguments(\n    output_dir='./results',\n    evaluation_strategy='epoch',\n    save_strategy='epoch',\n    logging_strategy='steps',\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    num_train_epochs=3,\n    load_best_model_at_end=True,\n    metric_for_best_model='f1',\n    greater_is_better=True,\n    logging_steps=10,\n    report_to=\"none\"  \n)\n\ndef compute_metrics(p):\n    pred, labels = p\n    pred = np.argmax(pred, axis=1)\n    f1 = f1_score(labels, pred)\n    return {'f1': f1}\n\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train_data,\n    eval_dataset=test_data,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\neval_result = trainer.evaluate()\nf1_rubert_tiny2 = eval_result['eval_f1']\nprint(f'F1-score для rubert-tiny2: {f1_rubert_tiny2:.4f}')","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2024-11-13T21:02:20.124751Z","iopub.execute_input":"2024-11-13T21:02:20.125554Z","iopub.status.idle":"2024-11-13T21:04:25.010698Z","shell.execute_reply.started":"2024-11-13T21:02:20.125524Z","shell.execute_reply":"2024-11-13T21:04:25.009673Z"}},"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:436: FutureWarning: Passing the following arguments to `Accelerator` is deprecated and will be removed in version 1.0 of Accelerate: dict_keys(['dispatch_batches', 'split_batches', 'even_batches', 'use_seedable_sampler']). Please pass an `accelerate.DataLoaderConfiguration` instead: \ndataloader_config = DataLoaderConfiguration(dispatch_batches=None, split_batches=False, even_batches=True, use_seedable_sampler=True)\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='2433' max='2433' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [2433/2433 02:02, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n      <th>F1</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.128500</td>\n      <td>0.194455</td>\n      <td>0.890052</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.142000</td>\n      <td>0.211035</td>\n      <td>0.902542</td>\n    </tr>\n    <tr>\n      <td>3</td>\n      <td>0.155300</td>\n      <td>0.239447</td>\n      <td>0.895680</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='91' max='91' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [91/91 00:01]\n    </div>\n    "},"metadata":{}},{"name":"stdout","text":"F1-score для rubert-tiny2: 0.9025\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"","metadata":{},"outputs":[],"execution_count":null}]}